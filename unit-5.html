<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Unit V · Privacy-Preserving Data Intelligence</title>
  <link rel="stylesheet" href="assets/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>
<body class="unit-page">
  <header class="sub-hero">
    <div class="container sub-hero__content">
      <a class="back-link" href="index.html">← Back to course overview</a>
      <span class="sub-hero__tag">UNIT V</span>
      <h1>Privacy-Preserving Data Intelligence</h1>
      <p class="sub-hero__intro">Build analytical ecosystems that defend confidentiality end-to-end using federated models,
        cryptographic collaboration, and zero-trust controls.</p>
    </div>
  </header>

  <main class="unit-page__main container">
    <section class="unit-section">
      <h2>Unit Perspective</h2>
      <p>Unit V reframes advanced analytics through a privacy-first lens. You will connect machine learning innovation with
        responsible data governance, ensuring that insights can scale without exposing sensitive attributes or weakening
        public trust.</p>
    </section>

    <section class="unit-section">
      <h2>Unit Objectives</h2>
      <ul>
        <li>Design privacy-preserving machine learning (PPML) workflows that align with regulatory and ethical safeguards.</li>
        <li>Evaluate federated analytics patterns, from data residency guarantees to secure aggregation and governance.</li>
        <li>Compare secure multiparty computation, homomorphic encryption, and confidential AI for collaborative modelling.</li>
        <li>Architect zero-trust data fabrics with synthetic data governance, telemetry, and continuous verification.</li>
      </ul>
    </section>

    <section class="unit-section">
      <h2>Syllabus at a Glance</h2>
      <div class="syllabus-grid">
        <article class="syllabus-card">
          <h3>Privacy-Preserving ML</h3>
          <p>Engineer model pipelines with differential privacy, secure gradients, and explainability controls.</p>
        </article>
        <article class="syllabus-card">
          <h3>Federated Analytics</h3>
          <p>Coordinate distributed learning, secure aggregation, and cross-jurisdiction data residency policies.</p>
        </article>
        <article class="syllabus-card">
          <h3>Synthetic Data Governance</h3>
          <p>Balance utility and disclosure risk with governance frameworks for generation, validation, and lifecycle audits.</p>
        </article>
        <article class="syllabus-card">
          <h3>Secure Multiparty Computation</h3>
          <p>Apply secret sharing and garbled circuit protocols to co-analyse encrypted datasets.</p>
        </article>
        <article class="syllabus-card">
          <h3>Homomorphic Encryption</h3>
          <p>Assess partial vs. fully homomorphic schemes for privacy-preserving inference and feature engineering.</p>
        </article>
        <article class="syllabus-card">
          <h3>Confidential AI</h3>
          <p>Operationalise trusted execution environments, policy guardrails, and attestation pipelines for AI workloads.</p>
        </article>
        <article class="syllabus-card">
          <h3>Zero-Trust Data Architectures</h3>
          <p>Combine fine-grained access, micro-segmentation, and continuous monitoring to secure hybrid data fabrics.</p>
        </article>
      </div>
    </section>

    <section class="unit-section unit-highlight">
      <div class="unit-highlight__content">
        <div class="unit-highlight__text">
          <h2>Global Spotlight: Federated Analytics in Practice</h2>
          <p>Governments, health networks, and financial cooperatives increasingly rely on <strong>federated analytics</strong> to
            unlock shared intelligence without centralising raw records. Success depends on collaborative governance and
            cryptographic trust.</p>
          <ul>
            <li><strong>Operating model:</strong> establish data residency guardians, privacy stewards, and neutral orchestration hubs.</li>
            <li><strong>Privacy focus:</strong> deploy secure aggregation, differential privacy noise, and continual consent management.</li>
            <li><strong>Outcome:</strong> consistent insights across borders while upholding statutory protections and partner autonomy.</li>
          </ul>
        </div>
        <aside class="unit-highlight__aside">
          <h3>Implementation Checklist</h3>
          <ul>
            <li>Codify cross-organisation governance with memoranda of understanding and dispute resolution paths.</li>
            <li>Automate compliance evidence for residency, retention, and breach notification obligations.</li>
            <li>Instrument observability dashboards for training events, aggregation failures, and privacy budget burn-downs.</li>
          </ul>
        </aside>
      </div>
    </section>

    <section class="unit-section">
      <h2>Regulatory Intelligence for AI Engineering</h2>
      <p>Rapidly evolving statutes and executive actions demand privacy-preserving controls that span development,
        deployment, and oversight. Anchor your technical roadmap to these jurisdictional guardrails.</p>
      <div class="unit-section__grid">
        <div class="concept-card">
          <span class="concept-card__tag">EU AI Act</span>
          <h3>Risk-Driven Compliance</h3>
          <p>Classifies AI systems by risk tiers, imposing strict duties for high-risk deployments and transparency for
            general-purpose models.</p>
          <ul class="concept-card__list">
            <li>Map system components to risk classes and pre-register high-risk use cases with conformity assessments.</li>
            <li>Implement dataset governance, bias testing, and technical documentation pipelines to evidence compliance.</li>
            <li>Enable post-market monitoring with audit logs, incident reporting hooks, and human oversight controls.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">India DPDP Rules</span>
          <h3>Consent-First Automation</h3>
          <p>Digital Personal Data Protection mandates explicit consent, data fiduciary accountability, and rapid breach
            notifications for automated processing.</p>
          <ul class="concept-card__list">
            <li>Embed purpose and consent metadata into feature stores and automate revocation across model endpoints.</li>
            <li>Build grievance redressal APIs and data principal dashboards with real-time access and deletion controls.</li>
            <li>Instrument localisation, retention timers, and security safeguards for sensitive personal data flows.</li>
          </ul>
        </div>
        <div class="concept-card">
          <span class="concept-card__tag">US AI Executive Orders</span>
          <h3>Safe-by-Design Mandates</h3>
          <p>Federal directives emphasise model safety testing, supply chain security, and reporting of safety incidents and
            cyber risks.</p>
          <ul class="concept-card__list">
            <li>Integrate red-team evaluations, adversarial resilience tests, and continuous monitoring into CI/CD gates.</li>
            <li>Maintain software bills of materials, secure model provenance, and attestations for federal procurement.</li>
            <li>Coordinate with CISO offices on rapid incident disclosure, critical infrastructure alignment, and secure
              data sharing.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">Sector Mandates</span>
          <h3>Healthcare &amp; Fintech Expectations</h3>
          <p>HIPAA, FDA algorithmic guidance, PCI DSS, and FFIEC handbooks demand privacy-preserving analytics with resilient
            controls.</p>
          <ul class="concept-card__list">
            <li>Calibrate federated learning and PPML safeguards to protected health information and payment card data.</li>
            <li>Document model lifecycle changes for clinical validation, explainability, and consumer fairness reviews.</li>
            <li>Align audit evidence with HITRUST, SOC 2, and financial crime monitoring requirements.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="unit-section">
      <h2>Regulation-to-Engineering Alignment</h2>
      <p>Use this comparison matrix to translate policy triggers into actionable engineering and governance practices.</p>
      <div class="comparison-table-wrapper">
        <table class="comparison-table">
          <thead>
            <tr>
              <th>Regime</th>
              <th>Trigger Conditions</th>
              <th>Engineering Priorities</th>
              <th>Operational Evidence</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>EU AI Act</td>
              <td>High-risk classification, general-purpose AI obligations, fundamental rights impact</td>
              <td>Risk registries, conformity assessment tooling, explainability and robustness testing pipelines</td>
              <td>Model cards, technical documentation, incident reporting and corrective action logs</td>
            </tr>
            <tr>
              <td>India DPDP</td>
              <td>Processing personal data of Indian residents, significant data fiduciary designation</td>
              <td>Consent orchestration services, data localisation controls, automated breach detection and response</td>
              <td>Consent ledgers, retention schedules, Data Protection Board-ready breach reports</td>
            </tr>
            <tr>
              <td>US AI Executive Orders</td>
              <td>Safety-critical models, federal procurement, critical infrastructure integrations</td>
              <td>Secure model supply chains, adversarial evaluation labs, continuous monitoring integrations</td>
              <td>SBOM attestations, safety test summaries, cyber incident notification workflows</td>
            </tr>
            <tr>
              <td>Healthcare &amp; Fintech Mandates</td>
              <td>Protected health information, medical device software, payment data and anti-fraud obligations</td>
              <td>Differential privacy overlays, federated analytics for regulated datasets, explainability and fairness checks</td>
              <td>Regulatory validation packets, clinician/consumer transparency reports, compliance audit trails</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <section class="unit-section">
      <h2>Federated Intelligence Lifecycle</h2>
      <div class="identity-timeline">
        <div class="timeline-step">
          <span class="timeline-step__badge">01 · Scope</span>
          <h3>Use Case Alignment</h3>
          <p>Define measurable outcomes, sensitive attributes, and legal boundaries that constrain model objectives.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">02 · Prepare</span>
          <h3>Local Data Readiness</h3>
          <p>Standardise schemas, apply local anonymisation, and register datasets with federated catalogues.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">03 · Train</span>
          <h3>Distributed Learning</h3>
          <p>Execute on-device training rounds with secure aggregation, drift detection, and privacy budget enforcement.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">04 · Evaluate</span>
          <h3>Shared Validation</h3>
          <p>Benchmark federated models against fairness, robustness, and leakage metrics under multiparty review.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">05 · Deploy</span>
          <h3>Confidential Operations</h3>
          <p>Deliver models via trusted execution environments with attested binaries and continuous compliance monitoring.</p>
        </div>
      </div>
    </section>

    <section class="unit-section unit-section--split">
      <div class="unit-section__grid">
        <div class="concept-card">
          <span class="concept-card__tag">Secure Multiparty Computation</span>
          <h3>Cryptographic Collaboration</h3>
          <p>SMPC enables parties to jointly compute functions without revealing inputs. Architect hybrid protocols tuned to
            latency, bandwidth, and trust assumptions.</p>
          <ul class="concept-card__list">
            <li>Select additive secret sharing for linear models and garbled circuits for boolean logic.</li>
            <li>Mitigate traffic analysis with batching, padding, and secure communication overlays.</li>
            <li>Embed verifiable computation proofs to assure correctness across jurisdictions.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">Homomorphic Encryption</span>
          <h3>Compute on Encrypted Data</h3>
          <p>Homomorphic encryption (HE) keeps data encrypted during computation. Balance privacy gains against operational
            complexity with targeted deployment patterns.</p>
          <ul class="concept-card__list">
            <li>Use partially homomorphic schemes for scoring and aggregation; reserve FHE for high-value inference.</li>
            <li>Optimise ciphertext packing, parameter selection, and hardware acceleration to manage latency.</li>
            <li>Integrate HE with federated orchestration and SMPC for layered defence-in-depth.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="unit-section">
      <h2>Confidential AI Operations</h2>
      <div class="authentication-levels">
        <article class="level-card level-card--low">
          <h3>Model Ingress</h3>
          <p>Harden build pipelines with signed artefacts, reproducible training, and SBOM transparency before deploying to
            confidential computing enclaves.</p>
          <ul>
            <li>Enforce attestation for model weights, feature stores, and runtime dependencies.</li>
            <li>Apply role-based policy guardrails to prompt engineering and fine-tuning workflows.</li>
            <li>Continuously scan telemetry for side-channel signals and data exfiltration attempts.</li>
          </ul>
        </article>
        <article class="level-card level-card--substantial">
          <h3>Inference Control</h3>
          <p>Deliver predictions through trusted execution environments (TEEs) with privacy-preserving monitoring and usage
            constraints.</p>
          <ul>
            <li>Combine runtime encryption, secure enclaves, and rate-limited APIs for sensitive model access.</li>
            <li>Instrument policy-as-code to enforce purpose limitation and consent-aware logging.</li>
            <li>Adopt feedback loops for fairness, privacy loss, and adversarial probe detection.</li>
          </ul>
        </article>
        <article class="level-card level-card--high">
          <h3>Lifecycle Assurance</h3>
          <p>Sustain trustworthy AI operations with privacy budgets, red-team testing, and transparent accountability.</p>
          <ul>
            <li>Publish privacy impact reports, audit trails, and model cards for stakeholder oversight.</li>
            <li>Rotate cryptographic material and enclave attestations on a zero-trust cadence.</li>
            <li>Simulate breach scenarios to validate incident response across partners.</li>
          </ul>
        </article>
      </div>
    </section>

    <section class="unit-section unit-section--split">
      <div class="unit-section__grid">
        <div class="concept-card">
          <span class="concept-card__tag">Synthetic Data Governance</span>
          <h3>Policy &amp; Assurance</h3>
          <p>Establish oversight for generation, sharing, and retirement of synthetic datasets to minimise re-identification risk.</p>
          <ul class="concept-card__list">
            <li>Mandate privacy risk scoring (e.g., disclosure risk, membership inference) before release.</li>
            <li>Document provenance, model architecture, and seed datasets to support audits.</li>
            <li>Schedule periodic refresh and deletion cycles tied to business objectives and regulatory change.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">Zero-Trust Data Architecture</span>
          <h3>Trust Nothing, Verify Everything</h3>
          <p>Zero-trust principles extend from network controls to analytic workloads, ensuring every request is authenticated,
            authorised, and encrypted.</p>
          <ul class="concept-card__list">
            <li>Segment data planes with policy-driven micro-perimeters and just-in-time access tokens.</li>
            <li>Continuously evaluate device posture, user behaviour, and workload integrity before granting privileges.</li>
            <li>Integrate data lineage, anomaly detection, and kill switches for real-time containment.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="unit-section">
      <h2>Learning Studio</h2>
      <div class="learning-studio">
        <article class="studio-card">
          <h3>Workshop</h3>
          <p>Design a federated analytics charter that unites legal, security, and engineering roles around a common use case.</p>
        </article>
        <article class="studio-card">
          <h3>Design Sprint</h3>
          <p>Prototype a PPML pipeline that chains differential privacy, SMPC, and enclave inference for a regulated service.</p>
        </article>
        <article class="studio-card">
          <h3>Threat Modelling</h3>
          <p>Map adversarial pathways targeting synthetic data assets, HE keys, and TEE attestation flows.</p>
        </article>
      </div>
    </section>

    <section class="unit-section unit-section--accent">
      <div class="unit-section__grid">
        <div>
          <h2>Metrics That Matter</h2>
          <ul class="metrics-list">
            <li><strong>Privacy Budget Stewardship:</strong> percentage of PPML experiments that stay within approved epsilon thresholds.</li>
            <li><strong>Federated Coverage:</strong> proportion of partners contributing updates with validated secure aggregation.</li>
            <li><strong>Synthetic Data Confidence:</strong> mean disclosure risk score across synthetic datasets in production.</li>
            <li><strong>Zero-Trust Compliance:</strong> incidents automatically contained by policy-driven micro-segmentation.</li>
          </ul>
        </div>
        <aside class="unit-cta">
          <h3>Next Steps</h3>
          <p>Apply these practices in your capstone by layering cryptographic privacy controls onto analytics roadmaps.</p>
          <a class="hero__cta" href="index.html">Return to syllabus</a>
        </aside>
      </div>
    </section>

    <section class="unit-section">
      <h2>Readings &amp; Resources</h2>
      <ul>
        <li>European Data Protection Board. <em>Guidelines on the Use of Personal Data in AI and Machine Learning</em> — focus on privacy-preserving design patterns.</li>
        <li>Open Differential Privacy Initiative. <em>Federated Analytics Playbook</em> — implementation artefacts for secure aggregation and noise calibration.</li>
        <li>Confidential Computing Consortium. <em>Trusted Execution Environments for AI</em> — governance and attestation reference architectures.</li>
        <li>Global Synthetic Data Network. <em>Risk, Utility, and Assurance Framework</em> — maturity model for synthetic data lifecycle management.</li>
      </ul>
    </section>
  </main>

  <footer class="unit-page__footer">
    <div class="container">
      <p>© 2024 Data Privacy &amp; Security Learning Hub · Unit V Guide</p>
    </div>
  </footer>
</body>
</html>
