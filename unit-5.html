<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Unit V · Privacy-Preserving Data Intelligence</title>
  <link rel="stylesheet" href="assets/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>
<body class="unit-page">
  <header class="sub-hero">
    <div class="container sub-hero__content">
      <a class="back-link" href="index.html">← Back to course overview</a>
      <span class="sub-hero__tag">UNIT V</span>
      <h1>Privacy-Preserving Data Intelligence</h1>
      <p class="sub-hero__intro">Build analytical ecosystems that defend confidentiality end-to-end using federated models,
        cryptographic collaboration, and zero-trust controls.</p>
    </div>
  </header>

  <main class="unit-page__main container">
    <section class="unit-section">
      <h2>Unit Perspective</h2>
      <p>Unit V reframes advanced analytics through a privacy-first lens. You will connect machine learning innovation with
        responsible data governance, ensuring that insights can scale without exposing sensitive attributes or weakening
        public trust. Casework translates privacy-enhancing technologies&mdash;differential privacy, SMPC, federated
        learning, confidential AI&mdash;into operating models that satisfy NIST AI RMF functions and ISO/IEC 42001
        management system requirements while linking back to guardrails established in Units I&ndash;IV.</p>
    </section>

    <section class="unit-section">
      <h2>Unit Objectives</h2>
      <ul>
        <li>Design privacy-preserving machine learning (PPML) workflows that align with regulatory and ethical safeguards.</li>
        <li>Evaluate federated analytics patterns, from data residency guarantees to secure aggregation and governance.</li>
        <li>Compare secure multiparty computation, homomorphic encryption, and confidential AI for collaborative modelling.</li>
        <li>Architect zero-trust data fabrics with synthetic data governance, telemetry, and continuous verification.</li>
      </ul>
    </section>

    <section class="unit-section">
      <h2>Syllabus at a Glance</h2>
      <div class="syllabus-grid">
        <article class="syllabus-card">
          <h3>Privacy-Preserving ML</h3>
          <p>Engineer model pipelines with differential privacy, secure gradients, and explainability controls.</p>
        </article>
        <article class="syllabus-card">
          <h3>Federated Analytics</h3>
          <p>Coordinate distributed learning, secure aggregation, and cross-jurisdiction data residency policies.</p>
        </article>
        <article class="syllabus-card">
          <h3>Synthetic Data Governance</h3>
          <p>Balance utility and disclosure risk with governance frameworks for generation, validation, and lifecycle audits.</p>
        </article>
        <article class="syllabus-card">
          <h3>Secure Multiparty Computation</h3>
          <p>Apply secret sharing and garbled circuit protocols to co-analyse encrypted datasets.</p>
        </article>
        <article class="syllabus-card">
          <h3>Homomorphic Encryption</h3>
          <p>Assess partial vs. fully homomorphic schemes for privacy-preserving inference and feature engineering.</p>
        </article>
        <article class="syllabus-card">
          <h3>Confidential AI</h3>
          <p>Operationalise trusted execution environments, policy guardrails, and attestation pipelines for AI workloads.</p>
        </article>
        <article class="syllabus-card">
          <h3>Zero-Trust Data Architectures</h3>
          <p>Combine fine-grained access, micro-segmentation, and continuous monitoring to secure hybrid data fabrics.</p>
        </article>
      </div>
    </section>

    <section class="unit-section unit-highlight">
      <div class="unit-highlight__content">
        <div class="unit-highlight__text">
          <h2>Global Spotlight: Federated Analytics in Practice</h2>
          <p>Governments, health networks, and financial cooperatives increasingly rely on <strong>federated analytics</strong> to
            unlock shared intelligence without centralising raw records. Success depends on collaborative governance and
            cryptographic trust.</p>
          <ul>
            <li><strong>Operating model:</strong> establish data residency guardians, privacy stewards, and neutral orchestration hubs.</li>
            <li><strong>Privacy focus:</strong> deploy secure aggregation, differential privacy noise, and continual consent management.</li>
            <li id="unit5-outcome"><strong>Outcome:</strong> consistent insights across borders while upholding statutory protections and partner autonomy.</li>
          </ul>
        </div>
        <aside class="unit-highlight__aside">
          <h3>Implementation Checklist</h3>
          <ul>
            <li>Codify cross-organisation governance with memoranda of understanding and dispute resolution paths.</li>
            <li>Automate compliance evidence for residency, retention, and breach notification obligations.</li>
            <li>Instrument observability dashboards for training events, aggregation failures, and privacy budget burn-downs.</li>
          </ul>
        </aside>
      </div>
    </section>

    <section class="unit-section">
      <h2>Case Studies in Digital Identity Governance</h2>
      <div class="unit-section__grid">
        <article class="concept-card">
          <span class="concept-card__tag">Aadhaar 2.0</span>
          <h3>Adaptive Identity Stewardship</h3>
          <p>India's Unique Identification Authority is rolling out virtual IDs, tokenised authentication, and upgraded
            biometric standards to curb misuse while extending social protection programs.</p>
          <ul class="concept-card__list">
            <li>Segment high-risk verifications with step-up biometrics, consent receipts, and traceable audit trails.</li>
            <li>Deploy offline eKYC credentials so citizens can selectively disclose attributes without full identifier
              exposure.</li>
            <li>Measure privacy uplift with reduced grievance filings, minimised duplicate enrollments, and faster
              entitlement delivery.</li>
          </ul>
        </article>
        <article class="concept-card concept-card--accent">
          <span class="concept-card__tag">EU eIDAS 2.0</span>
          <h3>European Digital Identity Wallets</h3>
          <p>The updated eIDAS regulation standardises cross-border digital wallets with strong privacy controls,
            portability, and interoperability across member states.</p>
          <ul class="concept-card__list">
            <li>Adopt verifiable credentials with selective disclosure, revocation registries, and assurance levels aligned
              to sector risk.</li>
            <li>Coordinate supervisory sandboxes to test wallet providers for resilience, consent governance, and vendor
              neutrality.</li>
            <li>Track success via wallet adoption rates, cross-border service uptake, and privacy breach statistics.</li>
          </ul>
        </article>
        <article class="concept-card">
          <span class="concept-card__tag">Global Public Infrastructure</span>
          <h3>MOSIP &amp; Open Source Identity</h3>
          <p>Modular Open Source Identity Platform deployments in the Philippines and Ethiopia leverage open standards to
            deliver inclusive IDs with privacy-preserving modules.</p>
          <ul class="concept-card__list">
            <li>Localise policy guardrails for data minimisation, community consent, and independent oversight boards.</li>
            <li>Combine privacy-enhancing technologies with civil society monitoring to mitigate surveillance creep.</li>
            <li>Evaluate outcomes through accessibility audits, grievance resolution metrics, and ecosystem vendor
              diversity.</li>
          </ul>
        </article>
      </div>
    </section>

    <section class="unit-section">
      <h2>Regulatory Intelligence for AI Engineering</h2>
      <p>Rapidly evolving statutes and executive actions demand privacy-preserving controls that span development,
        deployment, and oversight. Anchor your technical roadmap to these jurisdictional guardrails.</p>
      <div class="unit-section__grid">
        <div class="concept-card">
          <span class="concept-card__tag">EU AI Act</span>
          <h3>Risk-Driven Compliance</h3>
          <p>Classifies AI systems by risk tiers, imposing strict duties for high-risk deployments and transparency for
            general-purpose models.</p>
          <ul class="concept-card__list">
            <li>Map system components to risk classes and pre-register high-risk use cases with conformity assessments.</li>
            <li>Implement dataset governance, bias testing, and technical documentation pipelines to evidence compliance.</li>
            <li>Enable post-market monitoring with audit logs, incident reporting hooks, and human oversight controls.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">India DPDP Rules</span>
          <h3>Consent-First Automation</h3>
          <p>Digital Personal Data Protection mandates explicit consent, data fiduciary accountability, and rapid breach
            notifications for automated processing.</p>
          <ul class="concept-card__list">
            <li>Embed purpose and consent metadata into feature stores and automate revocation across model endpoints.</li>
            <li>Build grievance redressal APIs and data principal dashboards with real-time access and deletion controls.</li>
            <li>Instrument localisation, retention timers, and security safeguards for sensitive personal data flows.</li>
          </ul>
        </div>
        <div class="concept-card">
          <span class="concept-card__tag">US AI Executive Orders</span>
          <h3>Safe-by-Design Mandates</h3>
          <p>Federal directives emphasise model safety testing, supply chain security, and reporting of safety incidents and
            cyber risks.</p>
          <ul class="concept-card__list">
            <li>Integrate red-team evaluations, adversarial resilience tests, and continuous monitoring into CI/CD gates.</li>
            <li>Maintain software bills of materials, secure model provenance, and attestations for federal procurement.</li>
            <li>Coordinate with CISO offices on rapid incident disclosure, critical infrastructure alignment, and secure
              data sharing.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">Sector Mandates</span>
          <h3>Healthcare &amp; Fintech Expectations</h3>
          <p>HIPAA, FDA algorithmic guidance, PCI DSS, and FFIEC handbooks demand privacy-preserving analytics with resilient
            controls.</p>
          <ul class="concept-card__list">
            <li>Calibrate federated learning and PPML safeguards to protected health information and payment card data.</li>
            <li>Document model lifecycle changes for clinical validation, explainability, and consumer fairness reviews.</li>
            <li>Align audit evidence with HITRUST, SOC 2, and financial crime monitoring requirements.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">AI Governance Standards</span>
          <h3>NIST AI RMF &amp; ISO/IEC 42001</h3>
          <p>Pair organisational risk management with auditable AI management systems to keep PET deployments accountable across the lifecycle.</p>
          <ul class="concept-card__list">
            <li>Trace Govern/Map/Measure/Manage tasks to Unit I policy artefacts and Unit II encryption controls.</li>
            <li>Operationalise ISO/IEC 42001 clauses for impact assessments, monitoring, and continuous improvement across SMPC and federated learning pilots.</li>
            <li>Publish cross-unit transparency reports connecting identity safeguards from Unit III and threat modeling from Unit IV to AI risk metrics.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="unit-section">
      <h2>Regulation-to-Engineering Alignment</h2>
      <p>Use this comparison matrix to translate policy triggers into actionable engineering and governance practices.</p>
      <div class="comparison-table-wrapper">
        <table class="comparison-table">
          <thead>
            <tr>
              <th>Regime</th>
              <th>Trigger Conditions</th>
              <th>Engineering Priorities</th>
              <th>Operational Evidence</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>EU AI Act</td>
              <td>High-risk classification, general-purpose AI obligations, fundamental rights impact</td>
              <td>Risk registries, conformity assessment tooling, explainability and robustness testing pipelines</td>
              <td>Model cards, technical documentation, incident reporting and corrective action logs</td>
            </tr>
            <tr>
              <td>India DPDP</td>
              <td>Processing personal data of Indian residents, significant data fiduciary designation</td>
              <td>Consent orchestration services, data localisation controls, automated breach detection and response</td>
              <td>Consent ledgers, retention schedules, Data Protection Board-ready breach reports</td>
            </tr>
            <tr>
              <td>US AI Executive Orders</td>
              <td>Safety-critical models, federal procurement, critical infrastructure integrations</td>
              <td>Secure model supply chains, adversarial evaluation labs, continuous monitoring integrations</td>
              <td>SBOM attestations, safety test summaries, cyber incident notification workflows</td>
            </tr>
            <tr>
              <td>Healthcare &amp; Fintech Mandates</td>
              <td>Protected health information, medical device software, payment data and anti-fraud obligations</td>
              <td>Differential privacy overlays, federated analytics for regulated datasets, explainability and fairness checks</td>
              <td>Regulatory validation packets, clinician/consumer transparency reports, compliance audit trails</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <section class="unit-section">
      <h2>Ethical Dialogues &amp; Futures</h2>
      <p>Blend technical diligence with social foresight by interrogating the broader consequences of digital identity
        innovation. Facilitate multi-disciplinary dialogues that surface risk, opportunity, and accountability.</p>
      <div class="syllabus-grid">
        <article class="syllabus-card">
          <h3>Surveillance &amp; Power Asymmetries</h3>
          <p>Map how advanced analytics can amplify state or corporate monitoring and design proportional safeguards and
            redress mechanisms.</p>
        </article>
        <article class="syllabus-card">
          <h3>Algorithmic Bias &amp; Discrimination</h3>
          <p>Investigate disparate impact in biometric recognition, credential issuance, and risk scoring; embed fairness
            benchmarks into PPML and auditing pipelines.</p>
        </article>
        <article class="syllabus-card">
          <h3>Accessibility &amp; Inclusion</h3>
          <p>Evaluate usability for low-connectivity environments, disability accommodations, and multilingual interfaces to
            ensure equitable participation.</p>
        </article>
        <article class="syllabus-card">
          <h3>Ethical Frameworks &amp; Governance</h3>
          <p>Reference frameworks such as the OECD AI Principles, AI Ethics Guidelines Global Inventory, and indigenous data
            sovereignty charters to align innovation with rights-respecting guardrails.</p>
        </article>
      </div>
    </section>

    <section class="unit-section">
      <h2>Federated Intelligence Lifecycle</h2>
      <div class="identity-timeline">
        <div class="timeline-step">
          <span class="timeline-step__badge">01 · Scope</span>
          <h3>Use Case Alignment</h3>
          <p>Define measurable outcomes, sensitive attributes, and legal boundaries that constrain model objectives.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">02 · Prepare</span>
          <h3>Local Data Readiness</h3>
          <p>Standardise schemas, apply local anonymisation, and register datasets with federated catalogues.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">03 · Train</span>
          <h3>Distributed Learning</h3>
          <p>Execute on-device training rounds with secure aggregation, drift detection, and privacy budget enforcement.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">04 · Evaluate</span>
          <h3>Shared Validation</h3>
          <p>Benchmark federated models against fairness, robustness, and leakage metrics under multiparty review.</p>
        </div>
        <div class="timeline-step">
          <span class="timeline-step__badge">05 · Deploy</span>
          <h3>Confidential Operations</h3>
          <p>Deliver models via trusted execution environments with attested binaries and continuous compliance monitoring.</p>
        </div>
      </div>
    </section>

    <section class="unit-section unit-section--split">
      <div class="unit-section__grid">
        <div class="concept-card">
          <span class="concept-card__tag">Secure Multiparty Computation</span>
          <h3>Cryptographic Collaboration</h3>
          <p>SMPC enables parties to jointly compute functions without revealing inputs. Architect hybrid protocols tuned to
            latency, bandwidth, and trust assumptions.</p>
          <ul class="concept-card__list">
            <li>Select additive secret sharing for linear models and garbled circuits for boolean logic.</li>
            <li>Mitigate traffic analysis with batching, padding, and secure communication overlays.</li>
            <li>Embed verifiable computation proofs to assure correctness across jurisdictions.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">Homomorphic Encryption</span>
          <h3>Compute on Encrypted Data</h3>
          <p>Homomorphic encryption (HE) keeps data encrypted during computation. Balance privacy gains against operational
            complexity with targeted deployment patterns.</p>
          <ul class="concept-card__list">
            <li>Use partially homomorphic schemes for scoring and aggregation; reserve FHE for high-value inference.</li>
            <li>Optimise ciphertext packing, parameter selection, and hardware acceleration to manage latency.</li>
            <li>Integrate HE with federated orchestration and SMPC for layered defence-in-depth.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="unit-section">
      <h2>Confidential AI Operations</h2>
      <div class="authentication-levels">
        <article class="level-card level-card--low">
          <h3>Model Ingress</h3>
          <p>Harden build pipelines with signed artefacts, reproducible training, and SBOM transparency before deploying to
            confidential computing enclaves.</p>
          <ul>
            <li>Enforce attestation for model weights, feature stores, and runtime dependencies.</li>
            <li>Apply role-based policy guardrails to prompt engineering and fine-tuning workflows.</li>
            <li>Continuously scan telemetry for side-channel signals and data exfiltration attempts.</li>
          </ul>
        </article>
        <article class="level-card level-card--substantial">
          <h3>Inference Control</h3>
          <p>Deliver predictions through trusted execution environments (TEEs) with privacy-preserving monitoring and usage
            constraints.</p>
          <ul>
            <li>Combine runtime encryption, secure enclaves, and rate-limited APIs for sensitive model access.</li>
            <li>Instrument policy-as-code to enforce purpose limitation and consent-aware logging.</li>
            <li>Adopt feedback loops for fairness, privacy loss, and adversarial probe detection.</li>
          </ul>
        </article>
        <article class="level-card level-card--high">
          <h3>Lifecycle Assurance</h3>
          <p>Sustain trustworthy AI operations with privacy budgets, red-team testing, and transparent accountability.</p>
          <ul>
            <li>Publish privacy impact reports, audit trails, and model cards for stakeholder oversight.</li>
            <li>Rotate cryptographic material and enclave attestations on a zero-trust cadence.</li>
            <li>Simulate breach scenarios to validate incident response across partners.</li>
          </ul>
        </article>
      </div>
    </section>

    <section class="unit-section unit-section--split">
      <div class="unit-section__grid">
        <div class="concept-card">
          <span class="concept-card__tag">Synthetic Data Governance</span>
          <h3>Policy &amp; Assurance</h3>
          <p>Establish oversight for generation, sharing, and retirement of synthetic datasets to minimise re-identification risk.</p>
          <ul class="concept-card__list">
            <li>Mandate privacy risk scoring (e.g., disclosure risk, membership inference) before release.</li>
            <li>Document provenance, model architecture, and seed datasets to support audits.</li>
            <li>Schedule periodic refresh and deletion cycles tied to business objectives and regulatory change.</li>
          </ul>
        </div>
        <div class="concept-card concept-card--accent">
          <span class="concept-card__tag">Zero-Trust Data Architecture</span>
          <h3>Trust Nothing, Verify Everything</h3>
          <p>Zero-trust principles extend from network controls to analytic workloads, ensuring every request is authenticated,
            authorised, and encrypted.</p>
          <ul class="concept-card__list">
            <li>Segment data planes with policy-driven micro-perimeters and just-in-time access tokens.</li>
            <li>Continuously evaluate device posture, user behaviour, and workload integrity before granting privileges.</li>
            <li>Integrate data lineage, anomaly detection, and kill switches for real-time containment.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="unit-section">
      <h2>Learning Studio</h2>
      <div class="learning-studio">
        <article class="studio-card">
          <h3>Workshop</h3>
          <p>Design a federated analytics charter that unites legal, security, and engineering roles around a common use case.</p>
        </article>
        <article class="studio-card">
          <h3>Design Sprint</h3>
          <p>Prototype a PPML pipeline that chains differential privacy, SMPC, and enclave inference for a regulated service.</p>
        </article>
        <article class="studio-card">
          <h3>Threat Modelling</h3>
          <p>Map adversarial pathways targeting synthetic data assets, HE keys, and TEE attestation flows.</p>
        </article>
      </div>
    </section>

    <section class="unit-section unit-section--accent">
      <div class="unit-section__grid">
        <div>
          <h2>Metrics That Matter</h2>
          <ul class="metrics-list">
            <li><strong>Privacy Budget Stewardship:</strong> percentage of PPML experiments that stay within approved epsilon thresholds.</li>
            <li><strong>Federated Coverage:</strong> proportion of partners contributing updates with validated secure aggregation.</li>
            <li><strong>Synthetic Data Confidence:</strong> mean disclosure risk score across synthetic datasets in production.</li>
            <li><strong>Zero-Trust Compliance:</strong> incidents automatically contained by policy-driven micro-segmentation.</li>
          </ul>
        </div>
        <aside class="unit-cta">
          <h3>Next Steps</h3>
          <p>Apply these practices in your capstone by layering cryptographic privacy controls onto analytics roadmaps.</p>
          <a class="hero__cta" href="index.html">Return to syllabus</a>
        </aside>
      </div>
    </section>

    <section class="unit-section" id="unit5-rubric">
      <h2>Lab Toolkit, Resources &amp; Rubric</h2>
      <p class="unit-section__intro">Streamline Unit V facilitation with a shared tool stack, authoritative references, and a grading rubric tied directly to the unit objectives.</p>
      <div class="documentation-flow">
        <div class="documentation-flow__column">
          <h3>Lab Toolkit</h3>
          <ul class="checklist">
            <li><span>TensorFlow Privacy &amp; PyTorch Opacus:</span> Implement differential privacy gradients, clipping, and noise accounting in PPML pipelines.</li>
            <li><span>Flower or FedML federated learning frameworks:</span> Orchestrate cross-silo and cross-device training with secure aggregation experiments.</li>
            <li><span>OpenMined PySyft &amp; PyGrid:</span> Prototype secure multiparty computation, remote tensors, and governance dashboards.</li>
            <li><span>Microsoft SEAL / PALISADE homomorphic encryption SDKs:</span> Evaluate encrypted inference and feature engineering workloads.</li>
            <li><span>Confidential computing sandboxes (Azure Confidential, GCP Confidential VMs, AWS Nitro Enclaves):</span> Test attestation flows, policy guardrails, and zero-trust data fabric integrations.</li>
          </ul>
        </div>
        <div class="documentation-flow__column">
          <h3>Resource Links</h3>
          <ul>
            <li><a href="https://www.tensorflow.org/responsible_ai/privacy" target="_blank" rel="noopener">TensorFlow Privacy guide</a> — design patterns for DP-SGD, accounting, and evaluation.</li>
            <li><a href="https://opacus.ai/" target="_blank" rel="noopener">PyTorch Opacus documentation</a> — tutorials for integrating differential privacy into training loops.</li>
            <li><a href="https://flower.dev/docs/" target="_blank" rel="noopener">Flower federated learning docs</a> — deployment guides for secure aggregation and experimentation.</li>
            <li><a href="https://www.openmined.org/" target="_blank" rel="noopener">OpenMined learning resources</a> — community labs for MPC, federated analytics, and governance.</li>
            <li><a href="https://github.com/microsoft/SEAL" target="_blank" rel="noopener">Microsoft SEAL</a> — homomorphic encryption reference implementations with performance benchmarks.</li>
          </ul>
        </div>
        <div class="documentation-flow__column">
          <h3>Assessment Rubric</h3>
          <table class="rubric-table">
            <thead>
              <tr>
                <th scope="col">Criteria</th>
                <th scope="col">Outcome Alignment</th>
                <th scope="col">Evidence of Mastery</th>
                <th scope="col">Weight</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>PPML Workflow Implementation</td>
                <td>Design Privacy-Preserving ML Workflows</td>
                <td>Notebook or pipeline includes DP configuration, evaluation metrics, and mitigation of accuracy/privacy trade-offs.</td>
                <td>25%</td>
              </tr>
              <tr>
                <td>Federated Analytics Governance</td>
                <td>Evaluate Federated Analytics</td>
                <td>Runbook documents federation topology, consent model, secure aggregation, and jurisdictional controls.</td>
                <td>20%</td>
              </tr>
              <tr>
                <td>Cryptographic Collaboration Strategy</td>
                <td>Compare MPC, HE, Confidential AI</td>
                <td>Design decision matrix covers MPC/HE/TEE options with risk, performance, and governance analysis.</td>
                <td>20%</td>
              </tr>
              <tr>
                <td>Zero-Trust Data Fabric Blueprint</td>
                <td>Architect Zero-Trust Data Fabrics</td>
                <td>Architecture diagram maps segmentation, policy enforcement, telemetry, and attestation checkpoints.</td>
                <td>20%</td>
              </tr>
              <tr>
                <td>Metrics &amp; Assurance Reporting</td>
                <td>All Outcomes</td>
                <td>Executive summary articulates KPIs/KRIs, compliance mapping, and continuous monitoring commitments.</td>
                <td>15%</td>
              </tr>
            </tbody>
          </table>
          <p class="rubric-note">Encourage teams to attach experiment logs, configuration files, and governance artefacts that substantiate each rubric element.</p>
        </div>
      </div>
    </section>

    <section class="unit-section">
      <h2>Indian Industry Spotlight &amp; Career Integration</h2>
      <p class="unit-section__intro">Demonstrate how privacy-preserving intelligence unlocks value for Indian employers while respecting sector-specific regulations and data residency mandates.</p>
      <div class="topic-grid">
        <article class="topic-card">
          <span class="topic-card__tag">IT Services</span>
          <h3>Analytics Centre of Excellence</h3>
          <ul class="topic-card__list">
            <li>Case study: Outline how Infosys and TCS use federated analytics to service EU retail clients from Indian delivery centres without centralising PII, referencing DPDP and GDPR data transfer clauses.</li>
            <li>Map ISO/IEC 27701 extensions and SOC 2 controls to managed analytics offerings that leverage confidential computing.</li>
            <li>Internship tie-in: Develop a privacy impact assessment accelerator that scores proposed analytics projects against DPDP purpose limitation and CERT-In breach readiness.</li>
          </ul>
        </article>
        <article class="topic-card">
          <span class="topic-card__tag">Fintech</span>
          <h3>Responsible Finance Intelligence</h3>
          <ul class="topic-card__list">
            <li>Example: Evaluate RBI regulatory sandbox pilots on privacy-preserving credit scoring using secure multiparty computation and differential privacy.</li>
            <li>Incorporate SEBI&rsquo;s alternative data advisories and RBI&rsquo;s digital lending guidelines when designing synthetic data governance for risk analytics.</li>
            <li>Project tie-in: Prototype a federated fraud detection model for a UPI PSP internship that respects NPCI tokenisation rules and DPDP notice obligations.</li>
          </ul>
        </article>
        <article class="topic-card">
          <span class="topic-card__tag">Gov-Tech</span>
          <h3>Public Interest Data Missions</h3>
          <ul class="topic-card__list">
            <li>Case study: Analyse National Digital Health Mission federated registries to highlight consent management, anonymisation, and research governance.</li>
            <li>Reference MeitY&rsquo;s India Data Accessibility &amp; Use Policy, National Data Governance Framework, and DigiLocker data exchange norms when structuring cross-agency collaborations.</li>
            <li>Internship tie-in: Design a Smart City analytics proof-of-concept that blends synthetic mobility data with citizen privacy dashboards aligned to DPDP fiduciary duties.</li>
          </ul>
        </article>
      </div>
      <div class="callout-panel">
        <h3>Regional Compliance Watchlist</h3>
        <p>Monitor DPDP rulemaking, RBI/SEBI model risk guidelines, IFSCA fintech sandbox norms, and MeitY&rsquo;s AI governance advisories to keep privacy-preserving analytics playbooks current.</p>
      </div>
    </section>

    <section class="unit-section">
      <div class="unit-section__header">
        <h2>Lesson Blueprint</h2>
        <p>Facilitate a 3.5-hour design studio focused on scaling privacy-preserving analytics with measurable guardrails.</p>
      </div>
      <div class="lesson-plan">
        <div class="lesson-plan__grid">
          <article class="lesson-card">
            <h3>Learning Objectives</h3>
            <ul>
              <li>Evaluate privacy-enhancing technologies (PETs) for cross-organisation data collaboration.</li>
              <li>Design governance and operating models that align PET deployments with DPDP, GDPR, and AI standards.</li>
              <li>Evidence PET effectiveness using telemetry, privacy budgets, and stakeholder reporting.</li>
            </ul>
            <details>
              <summary>Timing roadmap</summary>
              <p>Schedule 35 minutes for PET framing, 65 minutes for labs, and 30 minutes for consortium governance simulations.</p>
            </details>
          </article>
          <article class="lesson-card">
            <h3>Key Topics &amp; Vocabulary</h3>
            <ul>
              <li>Federated learning, SMPC, differential privacy, confidential computing.</li>
              <li>Privacy budgets, consent orchestration, oversight committees, assurance artefacts.</li>
              <li>Zero-trust data fabrics, telemetry strategies, and PET maturity models.</li>
            </ul>
            <details>
              <summary>Glossary board</summary>
              <p>Invite learners to map each term to a real or hypothetical project and capture dependencies on the shared board.</p>
            </details>
          </article>
          <article class="lesson-card">
            <h3>Learning Activities</h3>
            <ul>
              <li><em>Aurora Insights</em> consortium simulation exploring PET choices and partner governance.</li>
              <li>Federated analytics lab configuring secure aggregation, DP noise, and confidential enclaves.</li>
              <li>Stakeholder storytelling workshop producing executive-ready briefing artefacts.</li>
            </ul>
            <details>
              <summary>Interactive elements</summary>
              <p>Use the lab toggle to provide scenario injects (e.g., partner drop-off, regulator inquiry) that challenge operating models.</p>
            </details>
          </article>
          <article class="lesson-card">
            <h3>Discussion Prompts</h3>
            <ul>
              <li>How do you balance analytic utility with privacy loss budgets over time?</li>
              <li>Which governance rituals keep consortium partners aligned and accountable?</li>
              <li>What telemetry proves PET controls are working as designed?</li>
            </ul>
            <details>
              <summary>Facilitator guide</summary>
              <p>Capture responses in the worksheet to reinforce traceability between governance decisions and evidence artefacts.</p>
            </details>
          </article>
          <article class="lesson-card">
            <h3>Assessment &amp; Evidence</h3>
            <ul>
              <li>Complete the PET Deployment Planner detailing technology stack, governance, and assurance.</li>
              <li>Submit lab exports (privacy budget dashboards, enclave attestations) supporting your recommendations.</li>
              <li>Deliver a roadmap briefing outlining phased PET adoption with metrics and safeguards.</li>
            </ul>
            <details>
              <summary>Evaluation focus</summary>
              <p>Review integration of governance controls, clarity of risk trade-offs, and completeness of assurance artefacts.</p>
            </details>
          </article>
        </div>
      </div>
    </section>

    <section class="unit-section unit-section--reference">
      <h2>Instructional Resources</h2>
      <p class="unit-section__intro">Distribute curated artefacts so learners can explore PET trade-offs with real-world rigour.</p>
      <div class="resource-deck">
        <div class="resource-group">
          <h3>Readings &amp; Briefs</h3>
          <ul>
            <li><a href="assets/unit-5/case-study.md" download>Case Study: Aurora Insights Consortium</a> — sets the collaboration context.</li>
            <li><a href="assets/unit-5/worksheet.md" download>Worksheet: PET Deployment Planner</a> — structures decision logs.</li>
            <li>Supplement with NIST AI RMF profiles and ISO/IEC 42001 implementation guidance.</li>
          </ul>
        </div>
        <div class="resource-group">
          <h3>Labs &amp; Practice</h3>
          <ul>
            <li><a href="assets/unit-5/lab-guide.md" download>Lab Guide: Federated Analytics Studio</a> — orchestrates PET experiments.</li>
            <li>Sample synthetic datasets and secure aggregation scripts for hands-on exploration.</li>
            <li>Monitoring dashboard templates for privacy budget and model performance reporting.</li>
          </ul>
        </div>
        <div class="resource-group">
          <h3>Slides &amp; Facilitation</h3>
          <ul>
            <li><a href="assets/unit-5/slide-deck-outline.md" download>Slide Deck Outline: Privacy-Preserving Data Intelligence</a> — frame strategy and storytelling.</li>
            <li>Checklist for consortium governance meetings and decision logs.</li>
            <li>Interactive polling questions gauging partner readiness and risk appetite.</li>
          </ul>
        </div>
      </div>
      <div class="supplementary-links">
        <a href="assets/unit-5/case-study.md" download>Download the Aurora Insights case packet</a>
        <a href="assets/unit-5/worksheet.md" download>Download the PET Deployment Planner worksheet</a>
      </div>
    </section>

    <section class="unit-section unit-section--reference">
      <h2>Current Regulations &amp; Standards Alignment</h2>
      <p class="unit-section__intro">Keep Unit V innovations accountable by linking them to the shared <a href="index.html#regulation-reference">Regulations &amp; Standards Reference</a> when drafting playbooks and capstone briefs.</p>
      <div class="reference-pillars">
        <article class="reference-pillars__item">
          <h3>Global Privacy Regulations</h3>
          <ul>
            <li><strong>EU GDPR (Regulation (EU) 2016/679)</strong> — align PET deployments with AI transparency, DPIAs, and data subject rights expectations.</li>
            <li><strong>India DPDP Act 2023</strong> — ensure consent, grievance handling, and localisation guardrails extend to PPML and synthetic data workflows.</li>
            <li><strong>California CCPA/CPRA</strong> — document automated decision-making disclosures and opt-out handling for AI use cases.</li>
            <li><strong>Brazil LGPD</strong> — incorporate ANPD accountability and incident reporting requirements into PET governance.</li>
          </ul>
        </article>
        <article class="reference-pillars__item">
          <h3>Security &amp; Privacy Standards</h3>
          <ul>
            <li><strong>NIST Cybersecurity Framework 2.0</strong> — leverage the Govern and Identify functions to scope PET adoption and supply-chain dependencies.</li>
            <li><strong>NIST Privacy Framework 1.0</strong> — build profiles that codify PPML, differential privacy, and synthetic data safeguards.</li>
            <li><strong>ISO/IEC 27001:2022 &amp; 27002:2022</strong> — connect emerging analytics controls with updated risk and monitoring expectations.</li>
            <li><strong>ISO/IEC 27701:2019</strong> — extend PIMS processes to track PET assurances and accountability roles.</li>
          </ul>
        </article>
        <article class="reference-pillars__item">
          <h3>Identity &amp; Sector Guidance</h3>
          <ul>
            <li><strong>NIST SP 800-63-3 Digital Identity</strong> — ensure identity proofing and authentication guardrails persist in federated analytics flows.</li>
            <li><strong>FIDO Alliance Passkey &amp; WebAuthn L3</strong> — integrate phishing-resistant access to confidential computing and analytics consoles.</li>
            <li><strong>PCI DSS v4.0</strong> — validate PET and zero-trust controls for cardholder data analytics and reporting.</li>
          </ul>
        </article>
      </div>
      <p class="unit-reference-note">Reference this alignment when presenting PET prototypes, metrics, and capstone deliverables to confirm regulatory fitness.</p>
    </section>

    <section class="unit-section">
      <h2>Readings &amp; Resources</h2>
      <ul>
        <li>European Data Protection Board. <em>Guidelines on the Use of Personal Data in AI and Machine Learning</em> — focus on privacy-preserving design patterns.</li>
        <li>Open Differential Privacy Initiative. <em>Federated Analytics Playbook</em> — implementation artefacts for secure aggregation and noise calibration.</li>
        <li>Confidential Computing Consortium. <em>Trusted Execution Environments for AI</em> — governance and attestation reference architectures.</li>
        <li>Global Synthetic Data Network. <em>Risk, Utility, and Assurance Framework</em> — maturity model for synthetic data lifecycle management.</li>
      </ul>
    </section>
  </main>

  <footer class="unit-page__footer">
    <div class="container">
      <p>© 2024 Data Privacy &amp; Security Learning Hub · Unit V Guide</p>
    </div>
  </footer>
</body>
</html>
